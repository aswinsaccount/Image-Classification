{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "def _load_cifar10_batch(file): \n",
    "    import pickle as cPickle \n",
    "    fo = open(file, 'rb') \n",
    "    dict = cPickle.load(fo,encoding='latin1') \n",
    "    fo.close() \n",
    "    return dict['data'].reshape(-1, 32, 32, 3), dict['labels'] # reshaping the data to 32 x 32 x 3  \n",
    "print('Loading...') \n",
    "\n",
    "batch_fns = [os.path.join(\"/home/halfmirror/Documents/Python/Image Classification/\", 'cifar-10-batches-py', 'data_batch_' + str(i)) for i in range(1, 6)] \n",
    "data_batches = [_load_cifar10_batch(fn) for fn in batch_fns] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.vstack([data_batches[i][0] for i in range(len(data_batches))]).astype('float') \n",
    "labels_all = np.vstack([data_batches[i][1] for i in range(len(data_batches))]).flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the whole training set into 92:8\n",
    "seed=7\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "data_split = StratifiedShuffleSplit(n_splits=1, test_size=0.08,random_state=seed) #creating data_split object with 8% test size \n",
    "data_split.get_n_splits(data_all,labels_all)\n",
    "for i, j in data_split.split(data_all,labels_all):\n",
    "    split_data_92, split_data_8 = data_all[i], data_all[j]        \n",
    "    split_label_92, split_label_8 = labels_all[i], labels_all[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training set into 70 and 30\n",
    "train_test_split = StratifiedShuffleSplit(1, test_size=0.3,random_state=seed) #test_size=0.3 denotes that 30 % of the dataset is used for testing.\n",
    "for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n",
    "    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]     \n",
    "    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n",
    "train_data = train_data_70 #assigning to variable train_data\n",
    "train_labels = train_label_70 #assigning to variable train_labels\n",
    "test_data = test_data_30\n",
    "test_labels = test_label_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data :  (2800, 32, 32, 3)\n",
      "train_labels :  (2800,)\n",
      "test_data :  (1200, 32, 32, 3)\n",
      "test_labels :  (1200,)\n"
     ]
    }
   ],
   "source": [
    "print ('train_data : ', train_data.shape)\n",
    "print ('train_labels : ', train_labels.shape)\n",
    "print ('test_data : ', test_data.shape)\n",
    "print ('test_labels : ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 19.,  26.,  24.],\n",
       "        [ 26.,  39.,  52.],\n",
       "        [ 64.,  73.,  81.],\n",
       "        ...,\n",
       "        [ 93.,  93.,  94.],\n",
       "        [ 96.,  98.,  99.],\n",
       "        [100.,  99.,  95.]],\n",
       "\n",
       "       [[  0.,   1.,   2.],\n",
       "        [  3.,  15.,  33.],\n",
       "        [ 49.,  62.,  74.],\n",
       "        ...,\n",
       "        [ 79.,  78.,  82.],\n",
       "        [ 87.,  92.,  96.],\n",
       "        [ 99.,  99.,  98.]],\n",
       "\n",
       "       [[  0.,   0.,   0.],\n",
       "        [  0.,   6.,  16.],\n",
       "        [ 27.,  41.,  55.],\n",
       "        ...,\n",
       "        [ 75.,  80.,  85.],\n",
       "        [ 89.,  94.,  98.],\n",
       "        [ 99., 101., 103.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 41.,  46.,  54.],\n",
       "        [ 59.,  64.,  67.],\n",
       "        [ 67.,  66.,  65.],\n",
       "        ...,\n",
       "        [ 44.,  41.,  61.],\n",
       "        [ 98.,  89.,  37.],\n",
       "        [ 20.,  35.,  45.]],\n",
       "\n",
       "       [[ 46.,  55.,  65.],\n",
       "        [ 68.,  72.,  74.],\n",
       "        [ 74.,  74.,  72.],\n",
       "        ...,\n",
       "        [ 62.,  52.,  40.],\n",
       "        [ 31.,  27.,  22.],\n",
       "        [ 28.,  33.,  36.]],\n",
       "\n",
       "       [[ 48.,  56.,  64.],\n",
       "        [ 70.,  73.,  74.],\n",
       "        [ 73.,  73.,  74.],\n",
       "        ...,\n",
       "        [107.,  82.,  52.],\n",
       "        [ 45.,  44.,  37.],\n",
       "        [ 31.,  27.,  25.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  (2800, 32, 32, 3)\n",
      "test_data:  (1200, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# definition of normalization function\n",
    "def normalize(data, eps=1e-8): \n",
    "    data -= data.mean(axis=(1, 2, 3), keepdims=True) \n",
    "    std = np.sqrt(data.var(axis=(1, 2, 3), ddof=1, keepdims=True)) # calculating standard deviation\n",
    "    std[std < eps] = 1. \n",
    "    data /= std \n",
    "    return data \n",
    "# calling the function\n",
    "train_data = normalize(train_data) \n",
    "test_data = normalize(test_data)\n",
    "# prints the shape of train data and test data \n",
    "print ('train_data: ', train_data.shape)\n",
    "print ('test_data: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.10026262, -0.92360678, -0.97407988],\n",
       "        [-0.92360678, -0.59553163, -0.26745649],\n",
       "        [ 0.0353821 ,  0.26251105,  0.46440344],\n",
       "        ...,\n",
       "        [ 0.76724204,  0.76724204,  0.79247859],\n",
       "        [ 0.84295169,  0.89342479,  0.91866133],\n",
       "        [ 0.94389788,  0.91866133,  0.81771514]],\n",
       "\n",
       "       [[-1.57975707, -1.55452052, -1.52928397],\n",
       "        [-1.50404742, -1.20120882, -0.74695093],\n",
       "        [-0.34316614, -0.015091  ,  0.2877476 ],\n",
       "        ...,\n",
       "        [ 0.41393034,  0.3886938 ,  0.48963999],\n",
       "        [ 0.61582274,  0.74200549,  0.84295169],\n",
       "        [ 0.91866133,  0.91866133,  0.89342479]],\n",
       "\n",
       "       [[-1.57975707, -1.57975707, -1.57975707],\n",
       "        [-1.57975707, -1.42833777, -1.17597227],\n",
       "        [-0.89837023, -0.54505854, -0.19174684],\n",
       "        ...,\n",
       "        [ 0.31298415,  0.43916689,  0.56534964],\n",
       "        [ 0.66629584,  0.79247859,  0.89342479],\n",
       "        [ 0.91866133,  0.96913443,  1.01960753]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.54505854, -0.41887579, -0.21698339],\n",
       "        [-0.09080065,  0.0353821 ,  0.11109175],\n",
       "        [ 0.11109175,  0.0858552 ,  0.06061865],\n",
       "        ...,\n",
       "        [-0.46934889, -0.54505854, -0.04032755],\n",
       "        [ 0.89342479,  0.66629584, -0.64600473],\n",
       "        [-1.07502608, -0.69647783, -0.44411234]],\n",
       "\n",
       "       [[-0.41887579, -0.19174684,  0.06061865],\n",
       "        [ 0.1363283 ,  0.2372745 ,  0.2877476 ],\n",
       "        [ 0.2877476 ,  0.2877476 ,  0.2372745 ],\n",
       "        ...,\n",
       "        [-0.015091  , -0.26745649, -0.57029509],\n",
       "        [-0.79742403, -0.89837023, -1.02455298],\n",
       "        [-0.87313368, -0.74695093, -0.67124128]],\n",
       "\n",
       "       [[-0.36840269, -0.16651029,  0.0353821 ],\n",
       "        [ 0.1868014 ,  0.26251105,  0.2877476 ],\n",
       "        [ 0.26251105,  0.26251105,  0.2877476 ],\n",
       "        ...,\n",
       "        [ 1.12055373,  0.48963999, -0.26745649],\n",
       "        [-0.44411234, -0.46934889, -0.64600473],\n",
       "        [-0.79742403, -0.89837023, -0.94884333]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_flat:  (3072, 2800)\n",
      "test_data_flat:  (3072, 1200)\n"
     ]
    }
   ],
   "source": [
    "# Computing whitening matrix \n",
    "train_data_flat = train_data.reshape(train_data.shape[0], -1).T\n",
    "test_data_flat = test_data.reshape(test_data.shape[0], -1).T\n",
    "print('train_data_flat: ', train_data_flat.shape)\n",
    "print('test_data_flat: ', test_data_flat.shape)\n",
    "train_data_flat_t = train_data_flat.T\n",
    "test_data_flat_t = test_data_flat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# n_components specify the no.of components to keep\n",
    "train_data_pca = PCA(n_components=train_data_flat.shape[1]).fit_transform(train_data_flat)\n",
    "test_data_pca = PCA(n_components=test_data_flat.shape[1]).fit_transform(test_data_flat)\n",
    "train_data_pca = train_data_pca.T\n",
    "test_data_pca = test_data_pca.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.084122  ,  31.01747292,  31.71379104, ..., -10.19050468,\n",
       "        -9.38963984,  -8.25183206])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import color\n",
    "# # definition for SVD\n",
    "# def svdFeatures(input_data):\n",
    "#     svdArray_input_data=[]\n",
    "#     size = input_data.shape[0]\n",
    "#     for i in range (0,size):\n",
    "#         img=color.rgb2gray(input_data[i])\n",
    "#         U, s, V = np.linalg.svd(img, full_matrices=False);\n",
    "#         S=[s[i] for i in range(30)]\n",
    "#         svdArray_input_data.append(S)\n",
    "#         svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
    "#     return svdMatrix_input_data\n",
    "# # apply SVD for train and test data\n",
    "# train_data_svd=svdFeatures(train_data)\n",
    "# test_data_svd=svdFeatures(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm #Creating a svm classifier model\n",
    "\n",
    "clf = svm.SVC(gamma=.001,probability=True) #Model training\n",
    "\n",
    "clf.fit(train_data_flat_t, train_labels) #After being fitted, the model can then be used to predict the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
